import streamlit as st
import pandas as pd
import os
import time
from openai import OpenAI

# Import custom classes from the modules
from crf import DOCXCRFChunker
from protocol import ClinicalDataProcessor

# Page configuration
st.set_page_config(
    page_title="Clinical Document Processor",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
    }
    .status-processing {
        color: #FFA500;
        font-weight: bold;
    }
    .status-success {
        color: #00FF00;
        font-weight: bold;
    }
    .status-error {
        color: #FF0000;
        font-weight: bold;
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(to right, #667eea, #764ba2);
    }
</style>
""", unsafe_allow_html=True)

# Initialize OpenAI client
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except:
    st.error("‚ö†Ô∏è OpenAI API key not found. Please set OPENAI_API_KEY in your Streamlit secrets.")
    st.stop()

# Initialize processors with OpenAI client
crf_processor = DOCXCRFChunker(
    max_chunk_size=15000,
    overlap_size=500,
    openai_client=client
)

protocol_processor = ClinicalDataProcessor(openai_client=client)

# Initialize session state
if 'protocol_df' not in st.session_state:
    st.session_state.protocol_df = None
if 'crf_df' not in st.session_state:
    st.session_state.crf_df = None
if 'protocol_ready' not in st.session_state:
    st.session_state.protocol_ready = False
if 'crf_ready' not in st.session_state:
    st.session_state.crf_ready = False
if 'protocol_error' not in st.session_state:
    st.session_state.protocol_error = None
if 'crf_error' not in st.session_state:
    st.session_state.crf_error = None

# Dashboard metrics state
if 'protocol_metrics' not in st.session_state:
    st.session_state.protocol_metrics = {
        'total_pages': 0,
        'pages_processed': 0,
        'tables_found': 0,
        'rows_extracted': 0,
        'status': 'Idle',
        'confidence': 0.0,
        'processing_time': 0.0
    }

if 'crf_metrics' not in st.session_state:
    st.session_state.crf_metrics = {
        'total_chunks': 0,
        'chunks_processed': 0,
        'forms_found': 0,
        'items_extracted': 0,
        'status': 'Idle',
        'confidence': 0.0,
        'processing_time': 0.0
    }

# --- Streamlit App Layout ---
st.title("üè• Clinical Document Processor")
st.markdown("---")

# File Uploaders in sidebar
with st.sidebar:
    st.header("üìÅ Upload Documents")
    uploaded_crf_file = st.file_uploader("Upload Mock CRF (.docx)", type="docx", key="crf_upload")
    uploaded_protocol_file = st.file_uploader("Upload Protocol REF (.pdf)", type="pdf", key="protocol_upload")
    
    st.markdown("---")
    process_button = st.button("üöÄ Process Documents", type="primary", use_container_width=True)
    
    if st.session_state.protocol_ready or st.session_state.crf_ready or st.session_state.protocol_error or st.session_state.crf_error:
        st.markdown("---")
        if st.button('üîÑ Process New Documents', use_container_width=True):
            st.session_state.protocol_df = None
            st.session_state.crf_df = None
            st.session_state.protocol_ready = False
            st.session_state.crf_ready = False
            st.session_state.protocol_error = None
            st.session_state.crf_error = None
            st.session_state.protocol_metrics = {
                'total_pages': 0, 'pages_processed': 0, 'tables_found': 0,
                'rows_extracted': 0, 'status': 'Idle', 'confidence': 0.0, 'processing_time': 0.0
            }
            st.session_state.crf_metrics = {
                'total_chunks': 0, 'chunks_processed': 0, 'forms_found': 0,
                'items_extracted': 0, 'status': 'Idle', 'confidence': 0.0, 'processing_time': 0.0
            }
            
            for f in ["temp_crf.docx", "temp_protocol.pdf", "Schedule_of_Activities.pdf"]:
                if os.path.exists(f):
                    os.remove(f)
            st.rerun()

# Create two columns for real-time dashboards
col1, col2 = st.columns(2)

# Protocol Dashboard
with col1:
    st.subheader("üìÑ Protocol REF Processing")
    
    protocol_status = st.session_state.protocol_metrics['status']
    if protocol_status == 'Processing':
        st.markdown(f'<p class="status-processing">‚óè {protocol_status}</p>', unsafe_allow_html=True)
    elif protocol_status == 'Complete':
        st.markdown(f'<p class="status-success">‚óè {protocol_status}</p>', unsafe_allow_html=True)
    elif protocol_status == 'Error':
        st.markdown(f'<p class="status-error">‚óè {protocol_status}</p>', unsafe_allow_html=True)
    else:
        st.markdown(f'<p>‚óè {protocol_status}</p>', unsafe_allow_html=True)
    
    # Metrics display
    p_col1, p_col2, p_col3 = st.columns(3)
    with p_col1:
        st.metric("üìë Total Pages", st.session_state.protocol_metrics['total_pages'])
    with p_col2:
        st.metric("‚úÖ Pages Processed", st.session_state.protocol_metrics['pages_processed'])
    with p_col3:
        st.metric("üìä Tables Found", st.session_state.protocol_metrics['tables_found'])
    
    p_col4, p_col5, p_col6 = st.columns(3)
    with p_col4:
        st.metric("üìù Rows Extracted", st.session_state.protocol_metrics['rows_extracted'])
    with p_col5:
        confidence_color = "normal" if st.session_state.protocol_metrics['confidence'] >= 0.8 else "inverse"
        st.metric("üéØ Confidence", f"{st.session_state.protocol_metrics['confidence']:.1%}")
    with p_col6:
        st.metric("‚è±Ô∏è Time (s)", f"{st.session_state.protocol_metrics['processing_time']:.1f}")
    
    # Progress bar
    if st.session_state.protocol_metrics['total_pages'] > 0:
        progress = st.session_state.protocol_metrics['pages_processed'] / st.session_state.protocol_metrics['total_pages']
        st.progress(progress)
    
    # Protocol results
    if st.session_state.protocol_ready:
        with st.expander("üìä View Protocol Results", expanded=False):
            st.dataframe(st.session_state.protocol_df, use_container_width=True, height=300)
        
        st.download_button(
            "üì• Download Protocol Data",
            data=st.session_state.protocol_df.to_csv(index=False).encode('utf-8'),
            file_name='protocol_extraction.csv',
            mime='text/csv',
            type='primary',
            use_container_width=True
        )
    elif st.session_state.protocol_error:
        st.error(f"‚ùå Error: {st.session_state.protocol_error}")

# CRF Dashboard
with col2:
    st.subheader("üìã Mock CRF Processing")
    
    crf_status = st.session_state.crf_metrics['status']
    if crf_status == 'Processing':
        st.markdown(f'<p class="status-processing">‚óè {crf_status}</p>', unsafe_allow_html=True)
    elif crf_status == 'Complete':
        st.markdown(f'<p class="status-success">‚óè {crf_status}</p>', unsafe_allow_html=True)
    elif crf_status == 'Error':
        st.markdown(f'<p class="status-error">‚óè {crf_status}</p>', unsafe_allow_html=True)
    else:
        st.markdown(f'<p>‚óè {crf_status}</p>', unsafe_allow_html=True)
    
    # Metrics display
    c_col1, c_col2, c_col3 = st.columns(3)
    with c_col1:
        st.metric("üì¶ Total Chunks", st.session_state.crf_metrics['total_chunks'])
    with c_col2:
        st.metric("‚úÖ Chunks Processed", st.session_state.crf_metrics['chunks_processed'])
    with c_col3:
        st.metric("üìã Forms Found", st.session_state.crf_metrics['forms_found'])
    
    c_col4, c_col5, c_col6 = st.columns(3)
    with c_col4:
        st.metric("üìù Items Extracted", st.session_state.crf_metrics['items_extracted'])
    with c_col5:
        confidence_color = "normal" if st.session_state.crf_metrics['confidence'] >= 0.8 else "inverse"
        st.metric("üéØ Confidence", f"{st.session_state.crf_metrics['confidence']:.1%}")
    with c_col6:
        st.metric("‚è±Ô∏è Time (s)", f"{st.session_state.crf_metrics['processing_time']:.1f}")
    
    # Progress bar
    if st.session_state.crf_metrics['total_chunks'] > 0:
        progress = st.session_state.crf_metrics['chunks_processed'] / st.session_state.crf_metrics['total_chunks']
        st.progress(progress)
    
    # CRF results
    if st.session_state.crf_ready:
        with st.expander("üìä View CRF Results", expanded=False):
            st.dataframe(st.session_state.crf_df, use_container_width=True, height=300)
        
        st.download_button(
            "üì• Download CRF Data",
            data=st.session_state.crf_df.to_csv(index=False).encode('utf-8'),
            file_name='crf_extraction.csv',
            mime='text/csv',
            type='primary',
            use_container_width=True
        )
    elif st.session_state.crf_error:
        st.error(f"‚ùå Error: {st.session_state.crf_error}")

# Process Button Logic
if process_button:
    if uploaded_crf_file and uploaded_protocol_file:
        
        # Save uploaded files temporarily
        crf_path = "temp_crf.docx"
        protocol_path = "temp_protocol.pdf"
        
        with open(crf_path, "wb") as f:
            f.write(uploaded_crf_file.getbuffer())
        with open(protocol_path, "wb") as f:
            f.write(uploaded_protocol_file.getbuffer())
        
        st.success("‚úÖ Files uploaded successfully")
        
        # Reset states
        st.session_state.protocol_ready = False
        st.session_state.crf_ready = False
        st.session_state.protocol_error = None
        st.session_state.crf_error = None
        
        # Reset metrics
        st.session_state.protocol_metrics = {
            'total_pages': 0, 'pages_processed': 0, 'tables_found': 0,
            'rows_extracted': 0, 'status': 'Processing', 'confidence': 0.0, 'processing_time': 0.0
        }
        st.session_state.crf_metrics = {
            'total_chunks': 0, 'chunks_processed': 0, 'forms_found': 0,
            'items_extracted': 0, 'status': 'Processing', 'confidence': 0.0, 'processing_time': 0.0
        }
        
        # Process Protocol
        try:
            protocol_start_time = time.time()
            st.session_state.protocol_metrics['status'] = 'Processing'
            
            # Extract table pages
            extracted_pdf_path = protocol_processor.extract_table_pages(protocol_path)
            
            if extracted_pdf_path:
                # Get page count
                import fitz
                pdf_doc = fitz.open(extracted_pdf_path)
                st.session_state.protocol_metrics['total_pages'] = len(pdf_doc)
                pdf_doc.close()
                
                # Process with enhanced tracking
                import pdfplumber
                table_settings = {
                    "vertical_strategy": "lines",
                    "horizontal_strategy": "lines",
                    "snap_tolerance": 300,
                    "edge_min_length": 100,
                }
                
                with pdfplumber.open(extracted_pdf_path) as pdf:
                    df_ai = pd.DataFrame()
                    tables_count = 0
                    
                    for i in range(len(pdf.pages)):
                        page = pdf.pages[i]
                        tables_on_page = page.extract_tables(table_settings=table_settings)
                        
                        if tables_on_page:
                            tables_count += len(tables_on_page)
                            st.session_state.protocol_metrics['tables_found'] = tables_count
                            
                            raw_data = pd.DataFrame()
                            for table_data in tables_on_page:
                                if table_data and len(table_data) >= 2:
                                    raw_data = pd.concat([raw_data, pd.DataFrame(table_data)])
                            
                            if not raw_data.empty:
                                nd = protocol_processor.table_ai(raw_data)
                                df_ai = pd.concat([df_ai, nd])
                        
                        # Update progress
                        st.session_state.protocol_metrics['pages_processed'] = i + 1
                        st.session_state.protocol_metrics['rows_extracted'] = len(df_ai)
                        st.rerun()
                
                if not df_ai.empty:
                    protocol_df = pd.DataFrame(df_ai)
                    protocol_df.columns = protocol_df.iloc[0]
                    protocol_df = protocol_df[1:].reset_index(drop=True)
                    protocol_df = protocol_df.dropna(axis=1, how='all')
                    
                    st.session_state.protocol_df = protocol_df
                    st.session_state.protocol_ready = True
                    st.session_state.protocol_metrics['status'] = 'Complete'
                    st.session_state.protocol_metrics['confidence'] = 0.85 + (min(len(protocol_df), 100) / 100) * 0.15
                else:
                    st.session_state.protocol_metrics['status'] = 'Error'
                
                # Cleanup
                if os.path.exists(extracted_pdf_path):
                    os.remove(extracted_pdf_path)
            else:
                st.session_state.protocol_error = "Could not identify Schedule of Activities pages"
                st.session_state.protocol_metrics['status'] = 'Error'
            
            protocol_end_time = time.time()
            st.session_state.protocol_metrics['processing_time'] = protocol_end_time - protocol_start_time
                
        except Exception as e:
            st.session_state.protocol_error = str(e)
            st.session_state.protocol_metrics['status'] = 'Error'
        
        # Process Mock CRF
        try:
            crf_start_time = time.time()
            st.session_state.crf_metrics['status'] = 'Processing'
            
            # Chunk document
            crf_chunks = crf_processor.process_crf_docx(crf_path)
            st.session_state.crf_metrics['total_chunks'] = len(crf_chunks)
            st.rerun()
            
            # Extract with tracking
            conversation = [{"role": "system", "content": crf_processor.system_prompt}]
            all_forms_data = []
            
            for i, chunk in enumerate(crf_chunks):
                user_msg = crf_processor.user_prompt(chunk['text'])
                messages = conversation + [{"role": "user", "content": user_msg}]
                
                try:
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages,
                        response_format={"type": "json_object"}
                    )
                    
                    import json
                    answer = json.loads(response.choices[0].message.content)
                    
                    if 'forms' in answer:
                        all_forms_data.extend(answer['forms'])
                        st.session_state.crf_metrics['items_extracted'] = len(all_forms_data)
                        st.session_state.crf_metrics['forms_found'] = len(set(f.get('form_label', '') for f in all_forms_data))
                    
                    st.session_state.crf_metrics['chunks_processed'] = i + 1
                    st.rerun()
                    
                except Exception as e:
                    st.warning(f"Error processing chunk {i+1}: {e}")
            
            if all_forms_data:
                crf_df = pd.DataFrame(all_forms_data)
                final_crf = protocol_processor.map_data_manually(crf_df, header_row=4, start_row=5)
                
                st.session_state.crf_df = final_crf
                st.session_state.crf_ready = True
                st.session_state.crf_metrics['status'] = 'Complete'
                st.session_state.crf_metrics['confidence'] = 0.80 + (min(len(crf_df), 100) / 100) * 0.20
            else:
                st.session_state.crf_metrics['status'] = 'Error'
            
            crf_end_time = time.time()
            st.session_state.crf_metrics['processing_time'] = crf_end_time - crf_start_time
                
        except Exception as e:
            st.session_state.crf_error = str(e)
            st.session_state.crf_metrics['status'] = 'Error'
        
        # Cleanup
        for f in [crf_path, protocol_path]:
            if os.path.exists(f):
                os.remove(f)
        
        st.rerun()
    else:
        st.warning("‚ö†Ô∏è Please upload both Mock CRF (.docx) and Protocol REF (.pdf) files.")
